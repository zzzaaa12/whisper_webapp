"""
æ‘˜è¦ API æœå‹™ - è™•ç†æ‘˜è¦æ•¸æ“šçš„è®€å–å’Œç®¡ç†
"""

import os
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional, Tuple
from src.utils.path_manager import get_path_manager
from src.utils.channel_mapping import get_display_name

class SummaryAPIService:
    """æ‘˜è¦ API æœå‹™é¡"""

    def __init__(self):
        self.path_manager = get_path_manager()
        self.summary_folder = self.path_manager.get_summary_folder()

    def get_latest_summaries(self, limit: int = 10) -> List[Dict]:
        """
        ç²å–æœ€æ–°çš„æ‘˜è¦åˆ—è¡¨

        Args:
            limit: è¿”å›çš„æ‘˜è¦æ•¸é‡é™åˆ¶

        Returns:
            List[Dict]: æ‘˜è¦åˆ—è¡¨ï¼ŒåŒ…å« index, title, created_at
        """
        try:
            # ç²å–æ‰€æœ‰ .txt æ‘˜è¦æ–‡ä»¶
            summary_files = []
            if self.summary_folder.exists():
                for file_path in self.summary_folder.glob("*.txt"):
                    if file_path.is_file():
                        # ç²å–æ–‡ä»¶ä¿®æ”¹æ™‚é–“
                        mtime = file_path.stat().st_mtime
                        summary_files.append({
                            'path': file_path,
                            'mtime': mtime,
                            'name': file_path.stem
                        })

            # æŒ‰ä¿®æ”¹æ™‚é–“æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
            summary_files.sort(key=lambda x: x['mtime'], reverse=True)

            # é™åˆ¶æ•¸é‡ä¸¦æ·»åŠ ç´¢å¼•
            result = []
            for i, file_info in enumerate(summary_files[:limit]):
                # è®€å–æ–‡ä»¶ç¬¬ä¸€è¡Œä½œç‚ºæ¨™é¡Œï¼Œå¦‚æœæ²’æœ‰å‰‡ä½¿ç”¨æ–‡ä»¶å
                title = self._extract_title(file_info['path'])

                result.append({
                    'index': i + 1,
                    'title': title,
                    'created_at': datetime.fromtimestamp(file_info['mtime']).strftime('%Y-%m-%d %H:%M:%S'),
                    'file_name': file_info['name']
                })

            return result

        except Exception as e:
            print(f"Error getting latest summaries: {e}")
            return []

    def get_summary_by_index(self, index: int) -> Optional[Dict]:
        """
        æ ¹æ“šç´¢å¼•ç²å–æ‘˜è¦å…§å®¹

        Args:
            index: æ‘˜è¦ç´¢å¼•ï¼ˆ1-5ï¼Œ1æ˜¯æœ€æ–°çš„ï¼‰

        Returns:
            Optional[Dict]: æ‘˜è¦è©³ç´°ä¿¡æ¯ï¼ŒåŒ…å« index, title, content, created_at, file_name
        """
        try:
            # é©—è­‰ç´¢å¼•ç¯„åœ
            if index < 1 or index > 10:
                return None

            # ç²å–æœ€æ–°çš„æ‘˜è¦åˆ—è¡¨
            summaries = self.get_latest_summaries(10)

            # æª¢æŸ¥ç´¢å¼•æ˜¯å¦å­˜åœ¨
            if index > len(summaries):
                return None

            # ç²å–å°æ‡‰çš„æ‘˜è¦ä¿¡æ¯
            summary_info = summaries[index - 1]

            # è®€å–å®Œæ•´å…§å®¹
            file_path = self.summary_folder / f"{summary_info['file_name']}.txt"
            content = self._read_file_content(file_path)

            if content is None:
                return None

            return {
                'index': index,
                'title': summary_info['title'],
                'content': content,
                'created_at': summary_info['created_at'],
                'file_name': summary_info['file_name']
            }

        except Exception as e:
            print(f"Error getting summary by index {index}: {e}")
            return None

    def _extract_title(self, file_path: Path) -> str:
        """
        å¾æ‘˜è¦æ–‡ä»¶ä¸­æå–æ¨™é¡Œ

        Args:
            file_path: æ–‡ä»¶è·¯å¾‘

        Returns:
            str: æ¨™é¡Œæ–‡æœ¬
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                first_line = f.readline().strip()

                # å¦‚æœç¬¬ä¸€è¡Œä¸ç‚ºç©ºä¸”ä¸å¤ªé•·ï¼Œä½¿ç”¨ä½œç‚ºæ¨™é¡Œ
                if first_line and len(first_line) <= 100:
                    # ç§»é™¤å¯èƒ½çš„æ¨™é¡Œæ¨™è¨˜
                    title = first_line.lstrip('#').strip()
                    if title:
                        return title

                # å¦å‰‡ä½¿ç”¨æ–‡ä»¶å
                return file_path.stem

        except Exception:
            # å¦‚æœè®€å–å¤±æ•—ï¼Œä½¿ç”¨æ–‡ä»¶å
            return file_path.stem

    def _read_file_content(self, file_path: Path) -> Optional[str]:
        """
        è®€å–æ–‡ä»¶å®Œæ•´å…§å®¹

        Args:
            file_path: æ–‡ä»¶è·¯å¾‘

        Returns:
            Optional[str]: æ–‡ä»¶å…§å®¹ï¼Œå¤±æ•—æ™‚è¿”å› None
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read().strip()
        except Exception as e:
            print(f"Error reading file {file_path}: {e}")
            return None

    def search_summary_by_title(self, search_title: str) -> Optional[Dict]:
        """
        æ ¹æ“šæ¨™é¡Œæœå°‹æ‘˜è¦æª”æ¡ˆï¼Œä½¿ç”¨èˆ‡è™•ç†ä½‡åˆ—ç›¸åŒçš„æª”åæ¯”å°é‚è¼¯

        Args:
            search_title: è¦æœå°‹çš„å½±ç‰‡æ¨™é¡Œ

        Returns:
            Optional[Dict]: æ‰¾åˆ°çš„æ‘˜è¦è©³ç´°ä¿¡æ¯ï¼ŒåŒ…å« title, content, created_at, file_name
        """
        try:
            if not search_title.strip():
                return None

            # ä½¿ç”¨èˆ‡ queue_worker ç›¸åŒçš„æª”åç”Ÿæˆé‚è¼¯
            from src.utils.file_sanitizer import sanitize_filename
            from src.utils.time_formatter import get_timestamp
            from src.utils.filename_matcher import FilenameMatcher
            from datetime import datetime

            # ç”Ÿæˆç•¶æ—¥çš„æ¨™é¡Œæ ¼å¼ (å› ç‚ºæˆ‘å€‘ä¸çŸ¥é“ç¢ºåˆ‡çš„è™•ç†æ—¥æœŸ)
            date_str = datetime.now().strftime('%Y.%m.%d')
            base_name = f"{date_str} - {search_title}"
            sanitized_title = sanitize_filename(base_name)

            # ä¹Ÿå˜—è©¦ Auto æ¨¡å¼çš„æ ¼å¼
            auto_sanitized_title = f"{date_str} - [Auto] " + sanitize_filename(search_title)

            # ä½¿ç”¨ FilenameMatcher æœå°‹ç›¸åŒå…§å®¹çš„æª”æ¡ˆ
            matching_files = []

            # æœå°‹ä¸€èˆ¬æ ¼å¼
            matching_files.extend(FilenameMatcher.find_matching_files(
                f"{sanitized_title}.txt", self.summary_folder, ['.txt']
            ))

            # æœå°‹ Auto æ ¼å¼
            matching_files.extend(FilenameMatcher.find_matching_files(
                f"{auto_sanitized_title}.txt", self.summary_folder, ['.txt']
            ))

            # æ‰¾åˆ°æœ€æ–°çš„æœ‰æ•ˆæ‘˜è¦æª”æ¡ˆ
            valid_files = []
            for file_path in matching_files:
                if file_path.is_file() and file_path.stat().st_size > 500:
                    valid_files.append((file_path, file_path.stat().st_mtime))

            if not valid_files:
                return None

            # é¸æ“‡æœ€æ–°çš„æª”æ¡ˆ
            latest_file_path, _ = max(valid_files, key=lambda x: x[1])

            # è®€å–æ‘˜è¦å…§å®¹
            content = self._read_file_content(latest_file_path)
            if content is None:
                return None

            title = self._extract_title(latest_file_path)
            mtime = latest_file_path.stat().st_mtime

            return {
                'title': title,
                'content': content,
                'created_at': datetime.fromtimestamp(mtime).strftime('%Y-%m-%d %H:%M:%S'),
                'file_name': latest_file_path.stem,
                'file_path': str(latest_file_path),
                'file_size': latest_file_path.stat().st_size
            }

        except Exception as e:
            print(f"Error searching summary by title '{search_title}': {e}")
            return None

    def get_summaries_list(self, page: int = 1, per_page: int = 30,
                          channel: Optional[str] = None,
                          search: Optional[str] = None,
                          bookmarked_only: bool = False,
                          bookmarked_files: Optional[List[str]] = None) -> Dict:
        """
        ç²å–æ‘˜è¦åˆ—è¡¨ï¼ˆæ”¯æ´åˆ†é ã€ç¯©é¸ã€æœå°‹ï¼‰

        Args:
            page: é ç¢¼ï¼ˆå¾1é–‹å§‹ï¼‰
            per_page: æ¯é æ•¸é‡
            channel: é »é“ç¯©é¸ï¼ˆåŸå§‹é »é“åç¨±æˆ–é¡¯ç¤ºåç¨±ï¼‰
            search: æœå°‹é—œéµå­—ï¼ˆæœå°‹æ¨™é¡Œï¼‰
            bookmarked_only: åªé¡¯ç¤ºæ›¸ç±¤
            bookmarked_files: æ›¸ç±¤æª”æ¡ˆåˆ—è¡¨ï¼ˆå¾å¤–éƒ¨å‚³å…¥ï¼Œé¿å…å¾ªç’°ä¾è³´ï¼‰

        Returns:
            Dict: åŒ…å« summariesï¼ˆæ‘˜è¦åˆ—è¡¨ï¼‰ã€paginationï¼ˆåˆ†é è³‡è¨Šï¼‰ã€channelsï¼ˆé »é“çµ±è¨ˆï¼‰
        """
        try:
            # ç²å–æ‰€æœ‰æ‘˜è¦æª”æ¡ˆ
            all_files = []
            if self.summary_folder.exists():
                for file_path in self.summary_folder.glob("*.txt"):
                    if file_path.is_file():
                        all_files.append(file_path)

            # æŒ‰ä¿®æ”¹æ™‚é–“æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
            all_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)

            # æå–æ‰€æœ‰æª”æ¡ˆçš„è³‡è¨Š
            all_summaries = []
            channel_counts = {}

            for file_path in all_files:
                # æå–é »é“å’Œæ¨™é¡Œ
                channel_name = self._extract_channel(file_path)
                title = self._extract_title(file_path)
                channel_display = get_display_name(channel_name)

                # çµ±è¨ˆé »é“æ•¸é‡
                if channel_display not in channel_counts:
                    channel_counts[channel_display] = {
                        'name': channel_name,
                        'display_name': channel_display,
                        'count': 0
                    }
                channel_counts[channel_display]['count'] += 1

                # æå–æ ¸å¿ƒä¸»é¡Œä½œç‚ºé è¦½
                preview = self._extract_core_topics(file_path)

                # å»ºç«‹æ‘˜è¦é …ç›®
                summary_item = {
                    'filename': file_path.name,
                    'title': title,
                    'channel': channel_name,
                    'channel_display': channel_display,
                    'created_at': datetime.fromtimestamp(file_path.stat().st_mtime).strftime('%Y-%m-%d %H:%M:%S'),
                    'file_size': file_path.stat().st_size,
                    'is_bookmarked': bookmarked_files and file_path.name in bookmarked_files,
                    'preview': preview
                }

                all_summaries.append(summary_item)

            # ç¯©é¸ï¼šæ›¸ç±¤
            if bookmarked_only and bookmarked_files:
                all_summaries = [s for s in all_summaries if s['is_bookmarked']]

            # ç¯©é¸ï¼šé »é“
            if channel:
                # åŒæ™‚æ”¯æ´åŸå§‹åç¨±å’Œé¡¯ç¤ºåç¨±
                all_summaries = [
                    s for s in all_summaries
                    if s['channel'] == channel or s['channel_display'] == channel
                ]

            # ç¯©é¸ï¼šæœå°‹
            if search:
                search_lower = search.lower()
                all_summaries = [
                    s for s in all_summaries
                    if search_lower in s['title'].lower()
                ]

            # è¨ˆç®—åˆ†é 
            total_count = len(all_summaries)
            total_pages = (total_count + per_page - 1) // per_page if total_count > 0 else 0

            # é©—è­‰é ç¢¼
            if page < 1:
                page = 1
            if page > total_pages and total_pages > 0:
                page = total_pages

            # è¨ˆç®—èµ·å§‹å’ŒçµæŸç´¢å¼•
            start_index = (page - 1) * per_page
            end_index = start_index + per_page

            # å–å¾—ç•¶å‰é çš„æ‘˜è¦
            page_summaries = all_summaries[start_index:end_index]

            # æ•´ç†é »é“åˆ—è¡¨ï¼ˆæŒ‰æ•¸é‡é™åºæ’åˆ—ï¼‰
            channels_list = sorted(
                channel_counts.values(),
                key=lambda x: (-x['count'], x['display_name'])
            )

            return {
                'summaries': page_summaries,
                'pagination': {
                    'page': page,
                    'per_page': per_page,
                    'total_count': total_count,
                    'total_pages': total_pages,
                    'has_next': page < total_pages,
                    'has_prev': page > 1
                },
                'channels': channels_list
            }

        except Exception as e:
            print(f"Error getting summaries list: {e}")
            return {
                'summaries': [],
                'pagination': {
                    'page': 1,
                    'per_page': per_page,
                    'total_count': 0,
                    'total_pages': 0,
                    'has_next': False,
                    'has_prev': False
                },
                'channels': []
            }

    def _extract_channel(self, file_path: Path) -> str:
        """
        å¾æ‘˜è¦æ–‡ä»¶ä¸­æå–é »é“ä¿¡æ¯

        Args:
            file_path: æ–‡ä»¶è·¯å¾‘

        Returns:
            str: é »é“åç¨±
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                # åªè®€å–å‰10è¡Œä¾†å°‹æ‰¾é »é“ä¿¡æ¯
                for i, line in enumerate(f):
                    if i > 10:
                        break

                    line = line.strip()

                    # å°‹æ‰¾ "ğŸ“º é »é“ï¼š" æ ¼å¼
                    if 'ğŸ“º é »é“ï¼š' in line:
                        return line.split('ğŸ“º é »é“ï¼š')[1].strip()
                    elif 'é »é“ï¼š' in line:
                        return line.split('é »é“ï¼š')[1].strip()

                return "æœªçŸ¥é »é“"
        except Exception:
            return "æœªçŸ¥é »é“"

    def _extract_core_topics(self, file_path: Path) -> str:
        """
        å¾æ‘˜è¦æ–‡ä»¶ä¸­æå–æ ¸å¿ƒä¸»é¡Œå…§å®¹ä½œç‚ºé è¦½

        Args:
            file_path: æ–‡ä»¶è·¯å¾‘

        Returns:
            str: æ ¸å¿ƒä¸»é¡Œå…§å®¹ï¼ˆæœ€å¤š200å­—ï¼‰
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()

                # å°‹æ‰¾æ ¸å¿ƒä¸»é¡Œå€å¡Š
                in_core_topics = False
                core_topics_lines = []

                for line in lines:
                    line_stripped = line.strip()

                    # æ‰¾åˆ°æ ¸å¿ƒä¸»é¡Œæ¨™é¡Œ
                    if 'æ ¸å¿ƒä¸»é¡Œ' in line_stripped and line_stripped.startswith('#'):
                        in_core_topics = True
                        continue

                    # å¦‚æœåœ¨æ ¸å¿ƒä¸»é¡Œå€å¡Šä¸­
                    if in_core_topics:
                        # é‡åˆ°ä¸‹ä¸€å€‹æ¨™é¡Œå°±åœæ­¢
                        if line_stripped.startswith('#'):
                            break

                        # æ”¶é›†éç©ºè¡Œ
                        if line_stripped and not line_stripped.startswith('='):
                            core_topics_lines.append(line_stripped)

                # åˆä½µå…§å®¹ä¸¦é™åˆ¶é•·åº¦
                if core_topics_lines:
                    content = ' '.join(core_topics_lines)
                    # é™åˆ¶åœ¨200å­—ä»¥å…§
                    if len(content) > 200:
                        content = content[:200] + '...'
                    return content

                return ""
        except Exception as e:
            print(f"Error extracting core topics from {file_path}: {e}")
            return ""


# å…¨åŸŸæœå‹™å¯¦ä¾‹
_summary_api_service = None

def get_summary_api_service() -> SummaryAPIService:
    """ç²å–æ‘˜è¦ API æœå‹™å¯¦ä¾‹"""
    global _summary_api_service
    if _summary_api_service is None:
        _summary_api_service = SummaryAPIService()
    return _summary_api_service